#!/usr/bin/env python3
"""
Smart Integration Orchestrator
×× ×”×œ ××™× ×˜×’×¨×¦×™×” ×—×›× ×œ×›×œ ××§×•×¨×•×ª ×”××™×“×¢
"""

import asyncio
import json
import os
import sys
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set, Tuple
import pandas as pd
import numpy as np
from collections import defaultdict
import logging
import schedule
import time
from dataclasses import dataclass, asdict
import subprocess

# ×”×’×“×¨×ª ×œ×•×’×™× ×’
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('smart_integration.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class IntegrationTask:
    """××©×™××ª ××™× ×˜×’×¨×¦×™×”"""
    name: str
    script: str
    priority: int
    frequency: str  # 'daily', 'weekly', 'hourly'
    last_run: Optional[datetime] = None
    success_count: int = 0
    failure_count: int = 0
    average_runtime: float = 0.0
    
class SmartIntegrationOrchestrator:
    """×× ×”×œ ××™× ×˜×’×¨×¦×™×” ×—×›×"""
    
    def __init__(self):
        self.tasks = self.initialize_tasks()
        self.running_tasks: Set[str] = set()
        self.results_cache: Dict[str, Dict] = {}
        self.api_limits = self.load_api_limits()
        self.database_path = "ğŸ‘‘_CEO-System/ğŸ¤–_Agents/ğŸª_7-Stores/ğŸ’¾_Smart-Database/"
        
    def initialize_tasks(self) -> List[IntegrationTask]:
        """××ª×—×•×œ ××©×™××•×ª"""
        return [
            IntegrationTask(
                name="LinkedIn Network Analysis",
                script="scripts/linkedin-network-analyzer.py",
                priority=1,
                frequency="daily"
            ),
            IntegrationTask(
                name="Sales Navigator Export",
                script="scripts/auto-sales-ql-export.js",
                priority=2,
                frequency="daily"
            ),
            IntegrationTask(
                name="Multi-Platform Scraping",
                script="scripts/advanced-platform-scraper.py",
                priority=3,
                frequency="weekly"
            ),
            IntegrationTask(
                name="Discord Communities",
                script="scripts/discord-smart-scraper.py",
                priority=4,
                frequency="daily"
            ),
            IntegrationTask(
                name="Company Research",
                script="scripts/company-employees-mapper.py",
                priority=5,
                frequency="weekly"
            ),
            IntegrationTask(
                name="Database Integration",
                script="scripts/integrate-candidates-to-database.py",
                priority=6,
                frequency="hourly"
            ),
            IntegrationTask(
                name="Cost Monitoring",
                script="scripts/cost-monitoring-dashboard.py",
                priority=7,
                frequency="hourly"
            )
        ]
        
    def load_api_limits(self) -> Dict[str, Dict]:
        """×˜×¢×™× ×ª ××’×‘×œ×•×ª API"""
        return {
            'linkedin': {
                'daily_limit': 1000,
                'hourly_limit': 100,
                'current_usage': 0
            },
            'sales_navigator': {
                'daily_limit': 2500,
                'export_limit': 100,
                'current_usage': 0
            },
            'github': {
                'hourly_limit': 5000,
                'current_usage': 0
            },
            'openai': {
                'monthly_budget': 50,
                'current_cost': 0
            }
        }
        
    async def run_orchestration(self):
        """×”×¨×¦×ª ×ª×”×œ×™×š ×”××•×¨×§×¡×˜×¨×¦×™×”"""
        logger.info("ğŸ¼ Starting Smart Integration Orchestrator")
        
        # ×”×’×“×¨×ª ×œ×•×— ×–×× ×™×
        self.setup_schedule()
        
        # ×œ×•×œ××ª ×¨×™×¦×” ×¨××©×™×ª
        while True:
            try:
                # ×‘×“×™×§×ª ××©×™××•×ª ××ª×•×–×× ×•×ª
                schedule.run_pending()
                
                # ×‘×“×™×§×ª ××©×™××•×ª ×“×—×•×¤×•×ª
                urgent_tasks = self.check_urgent_tasks()
                if urgent_tasks:
                    await self.execute_tasks(urgent_tasks)
                    
                # × ×™×ª×•×— ×ª×•×¦××•×ª ×•×—×™×‘×•×¨×™×
                await self.analyze_and_connect()
                
                # ×¢×“×›×•×Ÿ ×“×©×‘×•×¨×“
                self.update_dashboard()
                
                # ×”××ª× ×” ×§×¦×¨×”
                await asyncio.sleep(60)  # ×‘×“×™×§×” ×›×œ ×“×§×”
                
            except KeyboardInterrupt:
                logger.info("Orchestration stopped by user")
                break
            except Exception as e:
                logger.error(f"Orchestration error: {e}")
                await asyncio.sleep(300)  # ×”××ª× ×” 5 ×“×§×•×ª ×‘××§×¨×” ×©×œ ×©×’×™××”
                
    def setup_schedule(self):
        """×”×’×“×¨×ª ×œ×•×— ×–×× ×™×"""
        for task in self.tasks:
            if task.frequency == 'hourly':
                schedule.every().hour.do(lambda t=task: asyncio.create_task(self.run_task(t)))
            elif task.frequency == 'daily':
                schedule.every().day.at("09:00").do(lambda t=task: asyncio.create_task(self.run_task(t)))
            elif task.frequency == 'weekly':
                schedule.every().monday.at("10:00").do(lambda t=task: asyncio.create_task(self.run_task(t)))
                
    async def run_task(self, task: IntegrationTask):
        """×”×¨×¦×ª ××©×™××” ×‘×•×“×“×ª"""
        if task.name in self.running_tasks:
            logger.warning(f"Task {task.name} is already running, skipping")
            return
            
        self.running_tasks.add(task.name)
        start_time = datetime.now()
        
        try:
            logger.info(f"ğŸš€ Running task: {task.name}")
            
            # ×‘×“×™×§×ª ××’×‘×œ×•×ª API
            if not self.check_api_limits(task):
                logger.warning(f"API limits reached for {task.name}, postponing")
                return
                
            # ×”×¨×¦×ª ×”×¡×§×¨×™×¤×˜
            if task.script.endswith('.py'):
                result = await self.run_python_script(task.script)
            elif task.script.endswith('.js'):
                result = await self.run_node_script(task.script)
            else:
                logger.error(f"Unknown script type: {task.script}")
                return
                
            # ×¢×“×›×•×Ÿ ×¡×˜×˜×™×¡×˜×™×§×•×ª
            runtime = (datetime.now() - start_time).total_seconds()
            task.last_run = datetime.now()
            task.success_count += 1
            task.average_runtime = (task.average_runtime * (task.success_count - 1) + runtime) / task.success_count
            
            # ×©××™×¨×ª ×ª×•×¦××•×ª
            self.results_cache[task.name] = {
                'timestamp': datetime.now().isoformat(),
                'runtime': runtime,
                'result': result
            }
            
            logger.info(f"âœ… Task {task.name} completed in {runtime:.2f} seconds")
            
        except Exception as e:
            logger.error(f"âŒ Task {task.name} failed: {e}")
            task.failure_count += 1
            
        finally:
            self.running_tasks.remove(task.name)
            
    async def run_python_script(self, script_path: str) -> Dict:
        """×”×¨×¦×ª ×¡×§×¨×™×¤×˜ Python"""
        process = await asyncio.create_subprocess_exec(
            sys.executable, script_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            raise Exception(f"Script failed: {stderr.decode()}")
            
        # × ×™×¡×™×•×Ÿ ×œ×¤×¨×¡×¨ ××ª ×”×¤×œ×˜ ×›-JSON
        try:
            return json.loads(stdout.decode())
        except:
            return {'output': stdout.decode()}
            
    async def run_node_script(self, script_path: str) -> Dict:
        """×”×¨×¦×ª ×¡×§×¨×™×¤×˜ Node.js"""
        process = await asyncio.create_subprocess_exec(
            'node', script_path,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        stdout, stderr = await process.communicate()
        
        if process.returncode != 0:
            raise Exception(f"Script failed: {stderr.decode()}")
            
        # × ×™×¡×™×•×Ÿ ×œ×¤×¨×¡×¨ ××ª ×”×¤×œ×˜ ×›-JSON
        try:
            return json.loads(stdout.decode())
        except:
            return {'output': stdout.decode()}
            
    def check_api_limits(self, task: IntegrationTask) -> bool:
        """×‘×“×™×§×ª ××’×‘×œ×•×ª API"""
        # ×‘×“×™×§×” ×œ×¤×™ ×¡×•×’ ×”××©×™××”
        if 'linkedin' in task.script.lower():
            limit_info = self.api_limits['linkedin']
            return limit_info['current_usage'] < limit_info['daily_limit']
            
        elif 'sales' in task.script.lower():
            limit_info = self.api_limits['sales_navigator']
            return limit_info['current_usage'] < limit_info['daily_limit']
            
        return True  # ××™×Ÿ ××’×‘×œ×” ×œ××©×™××•×ª ××—×¨×•×ª
        
    def check_urgent_tasks(self) -> List[IntegrationTask]:
        """×‘×“×™×§×ª ××©×™××•×ª ×“×—×•×¤×•×ª"""
        urgent = []
        
        for task in self.tasks:
            # ××©×™××” ×©×œ× ×¨×¦×” ××–××Ÿ
            if task.last_run is None:
                urgent.append(task)
            elif task.frequency == 'hourly' and (datetime.now() - task.last_run) > timedelta(hours=2):
                urgent.append(task)
            elif task.frequency == 'daily' and (datetime.now() - task.last_run) > timedelta(days=2):
                urgent.append(task)
                
        return sorted(urgent, key=lambda x: x.priority)
        
    async def execute_tasks(self, tasks: List[IntegrationTask]):
        """×”×¨×¦×ª ××¡×¤×¨ ××©×™××•×ª"""
        # ×”×¨×¦×” ××§×‘×™×œ×™×ª ×©×œ ××©×™××•×ª
        await asyncio.gather(*[self.run_task(task) for task in tasks])
        
    async def analyze_and_connect(self):
        """× ×™×ª×•×— ×•×—×™×‘×•×¨ × ×ª×•× ×™×"""
        logger.info("ğŸ”— Analyzing and connecting data...")
        
        # ×˜×¢×™× ×ª ×›×œ ×”× ×ª×•× ×™× ×”×—×“×©×™×
        new_candidates = await self.load_new_candidates()
        new_companies = await self.load_new_companies()
        
        # ×”×¦×œ×‘×ª × ×ª×•× ×™×
        connections = self.cross_reference_data(new_candidates, new_companies)
        
        # ×¢×“×›×•×Ÿ ×ª×™×•×’×™× ×•×§×˜×’×•×¨×™×•×ª
        self.update_tags_and_categories(connections)
        
        # ×©××™×¨×” ×œ×××’×¨ ×”××¨×›×–×™
        await self.save_to_smart_database(connections)
        
        # ×™×¦×™×¨×ª ×”××œ×¦×•×ª
        recommendations = self.generate_smart_recommendations(connections)
        
        # ×©×œ×™×—×” ×œ×¡×•×›× ×™× ×¨×œ×•×•× ×˜×™×™×
        await self.notify_agents(recommendations)
        
    async def load_new_candidates(self) -> List[Dict]:
        """×˜×¢×™× ×ª ××•×¢××“×™× ×—×“×©×™×"""
        candidates = []
        
        # ×—×™×¤×•×© ×§×‘×¦×™ CSV ×—×“×©×™×
        for file in os.listdir('.'):
            if file.endswith('.csv') and 'candidates' in file:
                df = pd.read_csv(file)
                candidates.extend(df.to_dict('records'))
                
        return candidates
        
    async def load_new_companies(self) -> List[Dict]:
        """×˜×¢×™× ×ª ×—×‘×¨×•×ª ×—×“×©×•×ª"""
        companies = []
        
        # ×—×™×¤×•×© ×§×‘×¦×™ × ×ª×•× ×™×
        for file in os.listdir('.'):
            if file.endswith('.csv') and 'companies' in file:
                df = pd.read_csv(file)
                companies.extend(df.to_dict('records'))
                
        return companies
        
    def cross_reference_data(self, candidates: List[Dict], companies: List[Dict]) -> Dict:
        """×”×¦×œ×‘×ª × ×ª×•× ×™×"""
        connections = {
            'candidate_company_matches': [],
            'skill_clusters': defaultdict(list),
            'location_groups': defaultdict(list),
            'seniority_levels': defaultdict(list)
        }
        
        # ×™×¦×™×¨×ª ××¤×ª×—×•×ª ×œ×—×™×¤×•×© ××”×™×¨
        company_dict = {c['name'].lower(): c for c in companies if 'name' in c}
        
        for candidate in candidates:
            # ×”×ª×××” ×œ×—×‘×¨×”
            if 'current_company' in candidate:
                company_key = candidate['current_company'].lower()
                if company_key in company_dict:
                    connections['candidate_company_matches'].append({
                        'candidate': candidate,
                        'company': company_dict[company_key],
                        'match_strength': self.calculate_match_strength(candidate, company_dict[company_key])
                    })
                    
            # ×§×™×‘×•×¥ ×œ×¤×™ ×›×™×©×•×¨×™×
            if 'skills' in candidate:
                for skill in candidate['skills']:
                    connections['skill_clusters'][skill].append(candidate)
                    
            # ×§×™×‘×•×¥ ×œ×¤×™ ××™×§×•×
            if 'location' in candidate:
                connections['location_groups'][candidate['location']].append(candidate)
                
            # ×§×™×‘×•×¥ ×œ×¤×™ ×¨××ª ×‘×›×™×¨×•×ª
            seniority = self.extract_seniority(candidate.get('title', ''))
            connections['seniority_levels'][seniority].append(candidate)
            
        return connections
        
    def calculate_match_strength(self, candidate: Dict, company: Dict) -> float:
        """×—×™×©×•×‘ ×—×•×–×§ ×”×”×ª×××”"""
        score = 0.0
        
        # ×”×ª×××ª ×›×™×©×•×¨×™× ×œ×˜×›× ×•×œ×•×’×™×•×ª ×”×—×‘×¨×”
        if 'skills' in candidate and 'tech_stack' in company:
            matching_skills = set(candidate['skills']) & set(company['tech_stack'])
            score += len(matching_skills) * 0.2
            
        # ×”×ª×××ª ××™×§×•×
        if candidate.get('location') == company.get('location'):
            score += 0.3
            
        # ×”×ª×××ª ×’×•×“×œ ×—×‘×¨×” ×œ×”×¢×“×¤×•×ª
        if 'preferred_company_size' in candidate:
            if self.match_company_size(candidate['preferred_company_size'], company.get('size')):
                score += 0.2
                
        return min(score, 1.0)
        
    def extract_seniority(self, title: str) -> str:
        """×—×™×œ×•×¥ ×¨××ª ×‘×›×™×¨×•×ª ××ª×•××¨"""
        title_lower = title.lower()
        
        if any(word in title_lower for word in ['cto', 'ceo', 'vp', 'chief']):
            return 'executive'
        elif any(word in title_lower for word in ['director', 'head of', 'manager']):
            return 'management'
        elif any(word in title_lower for word in ['senior', 'lead', 'principal']):
            return 'senior'
        elif any(word in title_lower for word in ['junior', 'intern']):
            return 'junior'
        else:
            return 'mid-level'
            
    def update_tags_and_categories(self, connections: Dict):
        """×¢×“×›×•×Ÿ ×ª×™×•×’×™× ×•×§×˜×’×•×¨×™×•×ª"""
        # ×ª×™×•×’ ××•×¢××“×™× hot
        for match in connections['candidate_company_matches']:
            if match['match_strength'] > 0.8:
                match['candidate']['tags'] = match['candidate'].get('tags', [])
                match['candidate']['tags'].append('hot-candidate')
                
        # ×ª×™×•×’ skill experts
        for skill, candidates in connections['skill_clusters'].items():
            if len(candidates) < 10:  # ×›×™×©×•×¨ × ×“×™×¨
                for candidate in candidates:
                    candidate['tags'] = candidate.get('tags', [])
                    candidate['tags'].append(f'rare-skill-{skill}')
                    
    async def save_to_smart_database(self, connections: Dict):
        """×©××™×¨×” ×œ×××’×¨ ×”×—×›×"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ×©××™×¨×ª ×§×©×¨×™×
        with open(f"{self.database_path}connections_{timestamp}.json", 'w', encoding='utf-8') as f:
            json.dump(connections, f, ensure_ascii=False, indent=2)
            
        # ×¢×“×›×•×Ÿ ××™× ×“×§×¡ ×¨××©×™
        await self.update_master_index(connections)
        
    async def update_master_index(self, connections: Dict):
        """×¢×“×›×•×Ÿ ××™× ×“×§×¡ ×¨××©×™"""
        index_file = f"{self.database_path}master_index.json"
        
        # ×˜×¢×™× ×ª ××™× ×“×§×¡ ×§×™×™×
        if os.path.exists(index_file):
            with open(index_file, 'r', encoding='utf-8') as f:
                master_index = json.load(f)
        else:
            master_index = {
                'candidates': {},
                'companies': {},
                'skills': {},
                'last_updated': None
            }
            
        # ×¢×“×›×•×Ÿ × ×ª×•× ×™×
        for match in connections['candidate_company_matches']:
            candidate = match['candidate']
            if 'id' in candidate:
                master_index['candidates'][candidate['id']] = {
                    'name': candidate.get('name'),
                    'company': candidate.get('current_company'),
                    'skills': candidate.get('skills', []),
                    'last_seen': datetime.now().isoformat()
                }
                
        master_index['last_updated'] = datetime.now().isoformat()
        
        # ×©××™×¨×”
        with open(index_file, 'w', encoding='utf-8') as f:
            json.dump(master_index, f, ensure_ascii=False, indent=2)
            
    def generate_smart_recommendations(self, connections: Dict) -> List[Dict]:
        """×™×¦×™×¨×ª ×”××œ×¦×•×ª ×—×›××•×ª"""
        recommendations = []
        
        # ×”××œ×¦×” 1: ××•×¢××“×™× ×—××™×
        hot_candidates = [
            m for m in connections['candidate_company_matches']
            if m['match_strength'] > 0.8
        ]
        
        if hot_candidates:
            recommendations.append({
                'type': 'hot_candidates',
                'priority': 'high',
                'count': len(hot_candidates),
                'action': 'immediate_outreach',
                'candidates': hot_candidates[:10]
            })
            
        # ×”××œ×¦×” 2: ×××’×¨×™ ×›×™×©×¨×•× ×•×ª ×—×“×©×™×
        for skill, candidates in connections['skill_clusters'].items():
            if len(candidates) > 20:  # ×××’×¨ ×’×“×•×œ
                recommendations.append({
                    'type': 'talent_pool',
                    'skill': skill,
                    'size': len(candidates),
                    'action': 'create_targeted_campaign'
                })
                
        # ×”××œ×¦×” 3: ×—×‘×¨×•×ª ××˜×¨×” ×—×“×©×•×ª
        company_candidates = defaultdict(int)
        for match in connections['candidate_company_matches']:
            company_candidates[match['company']['name']] += 1
            
        for company, count in company_candidates.items():
            if count > 10:
                recommendations.append({
                    'type': 'target_company',
                    'company': company,
                    'candidate_count': count,
                    'action': 'company_focused_strategy'
                })
                
        return recommendations
        
    async def notify_agents(self, recommendations: List[Dict]):
        """×”×•×“×¢×” ×œ×¡×•×›× ×™× ×¨×œ×•×•× ×˜×™×™×"""
        for rec in recommendations:
            if rec['type'] == 'hot_candidates':
                # ×”×•×“×¢×” ×œ-Auto Recruiter
                await self.send_to_agent('auto-recruiter', rec)
                
            elif rec['type'] == 'talent_pool':
                # ×”×•×“×¢×” ×œ-Talent Sourcer
                await self.send_to_agent('talent-sourcer', rec)
                
            elif rec['type'] == 'target_company':
                # ×”×•×“×¢×” ×œ-Profile Analyzer
                await self.send_to_agent('profile-analyzer', rec)
                
    async def send_to_agent(self, agent_name: str, data: Dict):
        """×©×œ×™×—×ª × ×ª×•× ×™× ×œ×¡×•×›×Ÿ"""
        # ×›××Ÿ ×¦×¨×™×š implementation ×©×œ ×ª×§×©×•×¨×ª ×¢× ×”×¡×•×›× ×™×
        logger.info(f"Sending recommendation to {agent_name}: {data['type']}")
        
    def update_dashboard(self):
        """×¢×“×›×•×Ÿ ×“×©×‘×•×¨×“"""
        dashboard_data = {
            'timestamp': datetime.now().isoformat(),
            'tasks': [
                {
                    'name': task.name,
                    'last_run': task.last_run.isoformat() if task.last_run else None,
                    'success_rate': task.success_count / (task.success_count + task.failure_count) if (task.success_count + task.failure_count) > 0 else 0,
                    'average_runtime': task.average_runtime
                }
                for task in self.tasks
            ],
            'api_usage': self.api_limits,
            'recent_results': list(self.results_cache.values())[-10:]  # Last 10 results
        }
        
        with open('integration_dashboard.json', 'w', encoding='utf-8') as f:
            json.dump(dashboard_data, f, ensure_ascii=False, indent=2)
            
        logger.info("ğŸ“Š Dashboard updated")
        
    def match_company_size(self, preferred: str, actual: str) -> bool:
        """×”×ª×××ª ×’×•×“×œ ×—×‘×¨×”"""
        if not preferred or not actual:
            return False
            
        size_map = {
            'startup': ['1-50', '51-100'],
            'mid-size': ['100-500', '500-1000'],
            'enterprise': ['1000+', '5000+']
        }
        
        for pref_key in size_map:
            if pref_key in preferred.lower():
                return actual in size_map[pref_key]
                
        return False

async def main():
    """×¤×•× ×§×¦×™×” ×¨××©×™×ª"""
    orchestrator = SmartIntegrationOrchestrator()
    
    logger.info("ğŸ­ Smart Integration Orchestrator Started")
    logger.info(f"Managing {len(orchestrator.tasks)} integration tasks")
    
    # ×”×¨×¦×ª ×”××•×¨×§×¡×˜×¨×¦×™×”
    await orchestrator.run_orchestration()

if __name__ == "__main__":
    asyncio.run(main()) 